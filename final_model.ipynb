{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard launched at localhost:6006\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs\n",
    "print('Tensorboard launched at localhost:6006')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_run_dir(root='my_logs'):\n",
    "    return Path(root) / strftime('run_%Y_%m_%d_%H_%M_%S')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_score(true_values, predicted_values):\n",
    "    mae_ = mean_absolute_error(true_values, predicted_values)\n",
    "    mse_ = mean_squared_error(true_values, predicted_values)\n",
    "    r2_ = r2_score(true_values, predicted_values)\n",
    "\n",
    "    return mae_, mse_, r2_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_all_features.csv')\n",
    "\n",
    "dataset = dataset.loc[dataset['COND'] != '0']\n",
    "\n",
    "data = dataset.iloc[:, :-3]\n",
    "labels = dataset.iloc[:, -2:]\n",
    "\n",
    "data.drop(columns=['FACEATTRIBUTES-BLUR-BLURLEVEL', 'FACEATTRIBUTES-EXPOSURE-EXPOSURELEVEL', 'FACEATTRIBUTES-GENDER',\n",
    "                   'FACEATTRIBUTES-GLASSES', 'FACEATTRIBUTES-HAIR-INVISIBLE', 'FACEATTRIBUTES-MAKEUP-EYEMAKEUP',\n",
    "                   'FACEATTRIBUTES-MAKEUP-LIPMAKEUP', 'FACEATTRIBUTES-NOISE-NOISELEVEL',\n",
    "                   'FACEATTRIBUTES-ACCESSORIES', 'FACEID'],\n",
    "          inplace=True)\n",
    "\n",
    "data_train_full, data_test, labels_train_full, labels_test = train_test_split(data, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "data_train, data_validation, labels_train, labels_validation = train_test_split(data_train_full, labels_train_full, test_size=0.2, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 89)               179       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 89)                8010      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 89)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               46080     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,105,919\n",
      "Trainable params: 1,105,740\n",
      "Non-trainable params: 179\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_shape = data_train.shape[1]\n",
    "\n",
    "train_normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "train_normalizer.adapt(data_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    train_normalizer,\n",
    "    tf.keras.layers.Dense(train_shape, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2),\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "183/183 [==============================] - 2s 5ms/step - loss: 2.2640 - val_loss: 1.9924\n",
      "Epoch 2/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.9907 - val_loss: 1.9539\n",
      "Epoch 3/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.9438 - val_loss: 1.9237\n",
      "Epoch 4/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.9134 - val_loss: 1.9081\n",
      "Epoch 5/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.8851 - val_loss: 1.9022\n",
      "Epoch 6/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.8605 - val_loss: 1.8704\n",
      "Epoch 7/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.8385 - val_loss: 1.8551\n",
      "Epoch 8/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.8131 - val_loss: 1.8426\n",
      "Epoch 9/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.7890 - val_loss: 1.8245\n",
      "Epoch 10/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.7681 - val_loss: 1.8286\n",
      "Epoch 11/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.7441 - val_loss: 1.8167\n",
      "Epoch 12/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.7205 - val_loss: 1.7906\n",
      "Epoch 13/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.7016 - val_loss: 1.7949\n",
      "Epoch 14/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.6763 - val_loss: 1.7721\n",
      "Epoch 15/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.6524 - val_loss: 1.7688\n",
      "Epoch 16/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.6301 - val_loss: 1.7380\n",
      "Epoch 17/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.6080 - val_loss: 1.7681\n",
      "Epoch 18/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.5910 - val_loss: 1.7460\n",
      "Epoch 19/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.5610 - val_loss: 1.7280\n",
      "Epoch 20/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.5460 - val_loss: 1.7200\n",
      "Epoch 21/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.5259 - val_loss: 1.7043\n",
      "Epoch 22/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.5064 - val_loss: 1.7132\n",
      "Epoch 23/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.4846 - val_loss: 1.6922\n",
      "Epoch 24/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.4690 - val_loss: 1.6828\n",
      "Epoch 25/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.4414 - val_loss: 1.6903\n",
      "Epoch 26/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.4326 - val_loss: 1.6870\n",
      "Epoch 27/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.4153 - val_loss: 1.6737\n",
      "Epoch 28/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3973 - val_loss: 1.6672\n",
      "Epoch 29/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3818 - val_loss: 1.6540\n",
      "Epoch 30/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3646 - val_loss: 1.6549\n",
      "Epoch 31/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3452 - val_loss: 1.6315\n",
      "Epoch 32/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3331 - val_loss: 1.6482\n",
      "Epoch 33/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3138 - val_loss: 1.6394\n",
      "Epoch 34/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.3043 - val_loss: 1.6448\n",
      "Epoch 35/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2884 - val_loss: 1.6305\n",
      "Epoch 36/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2737 - val_loss: 1.6507\n",
      "Epoch 37/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2610 - val_loss: 1.6285\n",
      "Epoch 38/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2459 - val_loss: 1.6441\n",
      "Epoch 39/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2323 - val_loss: 1.6185\n",
      "Epoch 40/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2172 - val_loss: 1.5995\n",
      "Epoch 41/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.2049 - val_loss: 1.6020\n",
      "Epoch 42/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1912 - val_loss: 1.6084\n",
      "Epoch 43/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1813 - val_loss: 1.6091\n",
      "Epoch 44/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1721 - val_loss: 1.5892\n",
      "Epoch 45/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1571 - val_loss: 1.6094\n",
      "Epoch 46/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1439 - val_loss: 1.6078\n",
      "Epoch 47/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1360 - val_loss: 1.5718\n",
      "Epoch 48/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1193 - val_loss: 1.5757\n",
      "Epoch 49/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1120 - val_loss: 1.5875\n",
      "Epoch 50/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.1043 - val_loss: 1.5785\n",
      "Epoch 51/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0874 - val_loss: 1.5705\n",
      "Epoch 52/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0822 - val_loss: 1.5806\n",
      "Epoch 53/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0672 - val_loss: 1.5651\n",
      "Epoch 54/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0605 - val_loss: 1.5739\n",
      "Epoch 55/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0532 - val_loss: 1.5635\n",
      "Epoch 56/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0428 - val_loss: 1.5605\n",
      "Epoch 57/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0316 - val_loss: 1.5533\n",
      "Epoch 58/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0289 - val_loss: 1.5705\n",
      "Epoch 59/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0130 - val_loss: 1.5490\n",
      "Epoch 60/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 1.0083 - val_loss: 1.5598\n",
      "Epoch 61/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9943 - val_loss: 1.5673\n",
      "Epoch 62/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9944 - val_loss: 1.5517\n",
      "Epoch 63/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9800 - val_loss: 1.5562\n",
      "Epoch 64/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9732 - val_loss: 1.5344\n",
      "Epoch 65/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9612 - val_loss: 1.5306\n",
      "Epoch 66/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9550 - val_loss: 1.5435\n",
      "Epoch 67/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9479 - val_loss: 1.5324\n",
      "Epoch 68/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9452 - val_loss: 1.5408\n",
      "Epoch 69/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9282 - val_loss: 1.5293\n",
      "Epoch 70/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9302 - val_loss: 1.5218\n",
      "Epoch 71/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9129 - val_loss: 1.5410\n",
      "Epoch 72/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.9086 - val_loss: 1.5276\n",
      "Epoch 73/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8988 - val_loss: 1.5366\n",
      "Epoch 74/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8940 - val_loss: 1.5206\n",
      "Epoch 75/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8867 - val_loss: 1.5370\n",
      "Epoch 76/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8906 - val_loss: 1.5413\n",
      "Epoch 77/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8781 - val_loss: 1.5200\n",
      "Epoch 78/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8769 - val_loss: 1.5171\n",
      "Epoch 79/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.8639 - val_loss: 1.5280\n",
      "Epoch 80/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8569 - val_loss: 1.5285\n",
      "Epoch 81/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8445 - val_loss: 1.5336\n",
      "Epoch 82/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8414 - val_loss: 1.5190\n",
      "Epoch 83/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8365 - val_loss: 1.5091\n",
      "Epoch 84/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8380 - val_loss: 1.5067\n",
      "Epoch 85/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8312 - val_loss: 1.5185\n",
      "Epoch 86/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8247 - val_loss: 1.5240\n",
      "Epoch 87/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8181 - val_loss: 1.5215\n",
      "Epoch 88/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8060 - val_loss: 1.5089\n",
      "Epoch 89/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.8038 - val_loss: 1.5153\n",
      "Epoch 90/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7989 - val_loss: 1.5156\n",
      "Epoch 91/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.7972 - val_loss: 1.5099\n",
      "Epoch 92/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7891 - val_loss: 1.5089\n",
      "Epoch 93/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7884 - val_loss: 1.5141\n",
      "Epoch 94/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7794 - val_loss: 1.5128\n",
      "Epoch 95/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7761 - val_loss: 1.5217\n",
      "Epoch 96/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7792 - val_loss: 1.5074\n",
      "Epoch 97/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7685 - val_loss: 1.4947\n",
      "Epoch 98/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7628 - val_loss: 1.5122\n",
      "Epoch 99/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7560 - val_loss: 1.4956\n",
      "Epoch 100/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7487 - val_loss: 1.4984\n",
      "Epoch 101/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7465 - val_loss: 1.4971\n",
      "Epoch 102/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7471 - val_loss: 1.4971\n",
      "Epoch 103/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7402 - val_loss: 1.4917\n",
      "Epoch 104/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7348 - val_loss: 1.4993\n",
      "Epoch 105/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7329 - val_loss: 1.5026\n",
      "Epoch 106/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7252 - val_loss: 1.5124\n",
      "Epoch 107/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7202 - val_loss: 1.4968\n",
      "Epoch 108/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7171 - val_loss: 1.5184\n",
      "Epoch 109/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7134 - val_loss: 1.4919\n",
      "Epoch 110/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7134 - val_loss: 1.4962\n",
      "Epoch 111/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7128 - val_loss: 1.4949\n",
      "Epoch 112/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7075 - val_loss: 1.5032\n",
      "Epoch 113/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.7000 - val_loss: 1.5027\n",
      "Epoch 114/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6936 - val_loss: 1.4987\n",
      "Epoch 115/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6956 - val_loss: 1.4878\n",
      "Epoch 116/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6920 - val_loss: 1.5003\n",
      "Epoch 117/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6829 - val_loss: 1.4795\n",
      "Epoch 118/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6797 - val_loss: 1.4881\n",
      "Epoch 119/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6786 - val_loss: 1.4955\n",
      "Epoch 120/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6709 - val_loss: 1.4790\n",
      "Epoch 121/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6696 - val_loss: 1.4920\n",
      "Epoch 122/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6641 - val_loss: 1.4904\n",
      "Epoch 123/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6673 - val_loss: 1.5003\n",
      "Epoch 124/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6599 - val_loss: 1.4813\n",
      "Epoch 125/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6577 - val_loss: 1.4894\n",
      "Epoch 126/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6552 - val_loss: 1.4879\n",
      "Epoch 127/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6512 - val_loss: 1.4816\n",
      "Epoch 128/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6482 - val_loss: 1.4846\n",
      "Epoch 129/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6335 - val_loss: 1.4821\n",
      "Epoch 130/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6375 - val_loss: 1.4960\n",
      "Epoch 131/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6382 - val_loss: 1.4971\n",
      "Epoch 132/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6418 - val_loss: 1.4852\n",
      "Epoch 133/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6287 - val_loss: 1.4898\n",
      "Epoch 134/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6270 - val_loss: 1.4988\n",
      "Epoch 135/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6222 - val_loss: 1.5014\n",
      "Epoch 136/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6228 - val_loss: 1.4745\n",
      "Epoch 137/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6140 - val_loss: 1.4851\n",
      "Epoch 138/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6148 - val_loss: 1.4829\n",
      "Epoch 139/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6139 - val_loss: 1.4889\n",
      "Epoch 140/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6029 - val_loss: 1.4843\n",
      "Epoch 141/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6044 - val_loss: 1.4821\n",
      "Epoch 142/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6095 - val_loss: 1.4828\n",
      "Epoch 143/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6033 - val_loss: 1.4749\n",
      "Epoch 144/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6018 - val_loss: 1.4837\n",
      "Epoch 145/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5978 - val_loss: 1.4799\n",
      "Epoch 146/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.6028 - val_loss: 1.4829\n",
      "Epoch 147/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5901 - val_loss: 1.4684\n",
      "Epoch 148/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5893 - val_loss: 1.4787\n",
      "Epoch 149/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5823 - val_loss: 1.4729\n",
      "Epoch 150/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5888 - val_loss: 1.4793\n",
      "Epoch 151/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5800 - val_loss: 1.4772\n",
      "Epoch 152/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5777 - val_loss: 1.4770\n",
      "Epoch 153/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5756 - val_loss: 1.4770\n",
      "Epoch 154/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5740 - val_loss: 1.4629\n",
      "Epoch 155/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5688 - val_loss: 1.4735\n",
      "Epoch 156/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5693 - val_loss: 1.4761\n",
      "Epoch 157/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5659 - val_loss: 1.4714\n",
      "Epoch 158/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5695 - val_loss: 1.4720\n",
      "Epoch 159/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5604 - val_loss: 1.4772\n",
      "Epoch 160/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5556 - val_loss: 1.4826\n",
      "Epoch 161/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5512 - val_loss: 1.4839\n",
      "Epoch 162/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5538 - val_loss: 1.4733\n",
      "Epoch 163/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5542 - val_loss: 1.4756\n",
      "Epoch 164/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5537 - val_loss: 1.4783\n",
      "Epoch 165/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5456 - val_loss: 1.4591\n",
      "Epoch 166/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5420 - val_loss: 1.4629\n",
      "Epoch 167/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5458 - val_loss: 1.4655\n",
      "Epoch 168/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5408 - val_loss: 1.4818\n",
      "Epoch 169/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5414 - val_loss: 1.4661\n",
      "Epoch 170/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5361 - val_loss: 1.4888\n",
      "Epoch 171/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5308 - val_loss: 1.4729\n",
      "Epoch 172/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5324 - val_loss: 1.4744\n",
      "Epoch 173/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5279 - val_loss: 1.4662\n",
      "Epoch 174/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5381 - val_loss: 1.4703\n",
      "Epoch 175/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5306 - val_loss: 1.4707\n",
      "Epoch 176/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5251 - val_loss: 1.4572\n",
      "Epoch 177/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5219 - val_loss: 1.4632\n",
      "Epoch 178/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5343 - val_loss: 1.4647\n",
      "Epoch 179/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5256 - val_loss: 1.4516\n",
      "Epoch 180/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5165 - val_loss: 1.4715\n",
      "Epoch 181/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5196 - val_loss: 1.4705\n",
      "Epoch 182/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5252 - val_loss: 1.4573\n",
      "Epoch 183/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5179 - val_loss: 1.4697\n",
      "Epoch 184/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5040 - val_loss: 1.4529\n",
      "Epoch 185/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5044 - val_loss: 1.4608\n",
      "Epoch 186/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5010 - val_loss: 1.4435\n",
      "Epoch 187/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5104 - val_loss: 1.4520\n",
      "Epoch 188/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5070 - val_loss: 1.4582\n",
      "Epoch 189/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5014 - val_loss: 1.4564\n",
      "Epoch 190/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5075 - val_loss: 1.4666\n",
      "Epoch 191/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4947 - val_loss: 1.4622\n",
      "Epoch 192/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 1.4691\n",
      "Epoch 193/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4937 - val_loss: 1.4484\n",
      "Epoch 194/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.5015 - val_loss: 1.4460\n",
      "Epoch 195/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4947 - val_loss: 1.4587\n",
      "Epoch 196/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 1.4505\n",
      "Epoch 197/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 1.4585\n",
      "Epoch 198/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4963 - val_loss: 1.4734\n",
      "Epoch 199/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4952 - val_loss: 1.4639\n",
      "Epoch 200/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4877 - val_loss: 1.4682\n",
      "Epoch 201/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4883 - val_loss: 1.4666\n",
      "Epoch 202/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4799 - val_loss: 1.4530\n",
      "Epoch 203/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4826 - val_loss: 1.4811\n",
      "Epoch 204/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4806 - val_loss: 1.4613\n",
      "Epoch 205/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4747 - val_loss: 1.4457\n",
      "Epoch 206/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4754 - val_loss: 1.4546\n",
      "Epoch 207/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4703 - val_loss: 1.4526\n",
      "Epoch 208/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4644 - val_loss: 1.4560\n",
      "Epoch 209/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4722 - val_loss: 1.4621\n",
      "Epoch 210/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4701 - val_loss: 1.4632\n",
      "Epoch 211/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4654 - val_loss: 1.4662\n",
      "Epoch 212/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4688 - val_loss: 1.4562\n",
      "Epoch 213/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4718 - val_loss: 1.4486\n",
      "Epoch 214/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4647 - val_loss: 1.4711\n",
      "Epoch 215/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4594 - val_loss: 1.4500\n",
      "Epoch 216/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4615 - val_loss: 1.4571\n",
      "Epoch 217/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4504 - val_loss: 1.4513\n",
      "Epoch 218/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 1.4629\n",
      "Epoch 219/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4573 - val_loss: 1.4560\n",
      "Epoch 220/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4559 - val_loss: 1.4478\n",
      "Epoch 221/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4638 - val_loss: 1.4522\n",
      "Epoch 222/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4540 - val_loss: 1.4579\n",
      "Epoch 223/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4530 - val_loss: 1.4646\n",
      "Epoch 224/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4474 - val_loss: 1.4556\n",
      "Epoch 225/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4407 - val_loss: 1.4427\n",
      "Epoch 226/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4474 - val_loss: 1.4404\n",
      "Epoch 227/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4451 - val_loss: 1.4643\n",
      "Epoch 228/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4391 - val_loss: 1.4393\n",
      "Epoch 229/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4383 - val_loss: 1.4469\n",
      "Epoch 230/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4392 - val_loss: 1.4504\n",
      "Epoch 231/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4355 - val_loss: 1.4556\n",
      "Epoch 232/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4460 - val_loss: 1.4450\n",
      "Epoch 233/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4410 - val_loss: 1.4512\n",
      "Epoch 234/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4403 - val_loss: 1.4438\n",
      "Epoch 235/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4319 - val_loss: 1.4399\n",
      "Epoch 236/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4391 - val_loss: 1.4434\n",
      "Epoch 237/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4335 - val_loss: 1.4390\n",
      "Epoch 238/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4360 - val_loss: 1.4469\n",
      "Epoch 239/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4419 - val_loss: 1.4488\n",
      "Epoch 240/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4267 - val_loss: 1.4321\n",
      "Epoch 241/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4324 - val_loss: 1.4332\n",
      "Epoch 242/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4203 - val_loss: 1.4554\n",
      "Epoch 243/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4370 - val_loss: 1.4457\n",
      "Epoch 244/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4264 - val_loss: 1.4504\n",
      "Epoch 245/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4287 - val_loss: 1.4489\n",
      "Epoch 246/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4226 - val_loss: 1.4524\n",
      "Epoch 247/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4188 - val_loss: 1.4439\n",
      "Epoch 248/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4224 - val_loss: 1.4480\n",
      "Epoch 249/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 1.4473\n",
      "Epoch 250/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4194 - val_loss: 1.4482\n",
      "Epoch 251/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4157 - val_loss: 1.4511\n",
      "Epoch 252/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 1.4416\n",
      "Epoch 253/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4085 - val_loss: 1.4555\n",
      "Epoch 254/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4128 - val_loss: 1.4379\n",
      "Epoch 255/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 1.4234\n",
      "Epoch 256/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 1.4340\n",
      "Epoch 257/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 1.4392\n",
      "Epoch 258/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4138 - val_loss: 1.4453\n",
      "Epoch 259/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 1.4400\n",
      "Epoch 260/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 1.4490\n",
      "Epoch 261/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4046 - val_loss: 1.4442\n",
      "Epoch 262/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4040 - val_loss: 1.4464\n",
      "Epoch 263/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 1.4585\n",
      "Epoch 264/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 1.4434\n",
      "Epoch 265/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4000 - val_loss: 1.4482\n",
      "Epoch 266/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 1.4583\n",
      "Epoch 267/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3956 - val_loss: 1.4469\n",
      "Epoch 268/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 1.4315\n",
      "Epoch 269/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3979 - val_loss: 1.4531\n",
      "Epoch 270/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 1.4344\n",
      "Epoch 271/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3995 - val_loss: 1.4469\n",
      "Epoch 272/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3969 - val_loss: 1.4372\n",
      "Epoch 273/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3938 - val_loss: 1.4604\n",
      "Epoch 274/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3958 - val_loss: 1.4392\n",
      "Epoch 275/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3877 - val_loss: 1.4482\n",
      "Epoch 276/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3893 - val_loss: 1.4432\n",
      "Epoch 277/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3897 - val_loss: 1.4494\n",
      "Epoch 278/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3890 - val_loss: 1.4388\n",
      "Epoch 279/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3894 - val_loss: 1.4467\n",
      "Epoch 280/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3902 - val_loss: 1.4501\n",
      "Epoch 281/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3886 - val_loss: 1.4350\n",
      "Epoch 282/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3896 - val_loss: 1.4279\n",
      "Epoch 283/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3804 - val_loss: 1.4430\n",
      "Epoch 284/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3913 - val_loss: 1.4377\n",
      "Epoch 285/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3892 - val_loss: 1.4281\n",
      "Epoch 286/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3831 - val_loss: 1.4282\n",
      "Epoch 287/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3859 - val_loss: 1.4276\n",
      "Epoch 288/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3820 - val_loss: 1.4374\n",
      "Epoch 289/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3816 - val_loss: 1.4422\n",
      "Epoch 290/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3773 - val_loss: 1.4370\n",
      "Epoch 291/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3717 - val_loss: 1.4346\n",
      "Epoch 292/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3754 - val_loss: 1.4358\n",
      "Epoch 293/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3827 - val_loss: 1.4574\n",
      "Epoch 294/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3785 - val_loss: 1.4311\n",
      "Epoch 295/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3740 - val_loss: 1.4454\n",
      "Epoch 296/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3754 - val_loss: 1.4260\n",
      "Epoch 297/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3725 - val_loss: 1.4317\n",
      "Epoch 298/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3720 - val_loss: 1.4322\n",
      "Epoch 299/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3706 - val_loss: 1.4385\n",
      "Epoch 300/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3670 - val_loss: 1.4305\n",
      "Epoch 301/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3785 - val_loss: 1.4476\n",
      "Epoch 302/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3756 - val_loss: 1.4512\n",
      "Epoch 303/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 1.4396\n",
      "Epoch 304/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 1.4454\n",
      "Epoch 305/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3653 - val_loss: 1.4337\n",
      "Epoch 306/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3673 - val_loss: 1.4499\n",
      "Epoch 307/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3671 - val_loss: 1.4301\n",
      "Epoch 308/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3653 - val_loss: 1.4463\n",
      "Epoch 309/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3686 - val_loss: 1.4360\n",
      "Epoch 310/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3692 - val_loss: 1.4289\n",
      "Epoch 311/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3628 - val_loss: 1.4364\n",
      "Epoch 312/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3651 - val_loss: 1.4456\n",
      "Epoch 313/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3566 - val_loss: 1.4422\n",
      "Epoch 314/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3525 - val_loss: 1.4323\n",
      "Epoch 315/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3562 - val_loss: 1.4395\n",
      "Epoch 316/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3570 - val_loss: 1.4283\n",
      "Epoch 317/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3598 - val_loss: 1.4432\n",
      "Epoch 318/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3607 - val_loss: 1.4345\n",
      "Epoch 319/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3627 - val_loss: 1.4276\n",
      "Epoch 320/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3539 - val_loss: 1.4411\n",
      "Epoch 321/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3549 - val_loss: 1.4351\n",
      "Epoch 322/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3562 - val_loss: 1.4447\n",
      "Epoch 323/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3471 - val_loss: 1.4416\n",
      "Epoch 324/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3586 - val_loss: 1.4319\n",
      "Epoch 325/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3601 - val_loss: 1.4361\n",
      "Epoch 326/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3513 - val_loss: 1.4520\n",
      "Epoch 327/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 1.4375\n",
      "Epoch 328/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3529 - val_loss: 1.4361\n",
      "Epoch 329/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3560 - val_loss: 1.4495\n",
      "Epoch 330/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3588 - val_loss: 1.4338\n",
      "Epoch 331/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3469 - val_loss: 1.4469\n",
      "Epoch 332/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3463 - val_loss: 1.4218\n",
      "Epoch 333/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3411 - val_loss: 1.4209\n",
      "Epoch 334/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3433 - val_loss: 1.4180\n",
      "Epoch 335/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3425 - val_loss: 1.4385\n",
      "Epoch 336/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3413 - val_loss: 1.4303\n",
      "Epoch 337/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3435 - val_loss: 1.4375\n",
      "Epoch 338/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3427 - val_loss: 1.4297\n",
      "Epoch 339/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3444 - val_loss: 1.4341\n",
      "Epoch 340/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3426 - val_loss: 1.4332\n",
      "Epoch 341/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3378 - val_loss: 1.4296\n",
      "Epoch 342/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3334 - val_loss: 1.4343\n",
      "Epoch 343/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3320 - val_loss: 1.4345\n",
      "Epoch 344/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3377 - val_loss: 1.4184\n",
      "Epoch 345/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3366 - val_loss: 1.4339\n",
      "Epoch 346/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3312 - val_loss: 1.4366\n",
      "Epoch 347/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3413 - val_loss: 1.4434\n",
      "Epoch 348/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3451 - val_loss: 1.4489\n",
      "Epoch 349/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3364 - val_loss: 1.4439\n",
      "Epoch 350/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3397 - val_loss: 1.4349\n",
      "Epoch 351/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3269 - val_loss: 1.4402\n",
      "Epoch 352/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3337 - val_loss: 1.4271\n",
      "Epoch 353/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3281 - val_loss: 1.4216\n",
      "Epoch 354/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3263 - val_loss: 1.4296\n",
      "Epoch 355/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3275 - val_loss: 1.4357\n",
      "Epoch 356/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3279 - val_loss: 1.4432\n",
      "Epoch 357/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3290 - val_loss: 1.4473\n",
      "Epoch 358/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3343 - val_loss: 1.4474\n",
      "Epoch 359/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3334 - val_loss: 1.4490\n",
      "Epoch 360/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3336 - val_loss: 1.4392\n",
      "Epoch 361/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 1.4385\n",
      "Epoch 362/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3297 - val_loss: 1.4265\n",
      "Epoch 363/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3242 - val_loss: 1.4314\n",
      "Epoch 364/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3290 - val_loss: 1.4470\n",
      "Epoch 365/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3299 - val_loss: 1.4290\n",
      "Epoch 366/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3266 - val_loss: 1.4396\n",
      "Epoch 367/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3166 - val_loss: 1.4384\n",
      "Epoch 368/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3232 - val_loss: 1.4386\n",
      "Epoch 369/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3178 - val_loss: 1.4306\n",
      "Epoch 370/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3224 - val_loss: 1.4299\n",
      "Epoch 371/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3221 - val_loss: 1.4396\n",
      "Epoch 372/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3308 - val_loss: 1.4392\n",
      "Epoch 373/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3254 - val_loss: 1.4320\n",
      "Epoch 374/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3127 - val_loss: 1.4356\n",
      "Epoch 375/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 1.4345\n",
      "Epoch 376/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3195 - val_loss: 1.4345\n",
      "Epoch 377/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3205 - val_loss: 1.4316\n",
      "Epoch 378/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3142 - val_loss: 1.4226\n",
      "Epoch 379/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3180 - val_loss: 1.4246\n",
      "Epoch 380/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3153 - val_loss: 1.4359\n",
      "Epoch 381/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3206 - val_loss: 1.4329\n",
      "Epoch 382/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3236 - val_loss: 1.4281\n",
      "Epoch 383/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3174 - val_loss: 1.4313\n",
      "Epoch 384/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3188 - val_loss: 1.4213\n",
      "Epoch 385/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3151 - val_loss: 1.4389\n",
      "Epoch 386/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3174 - val_loss: 1.4444\n",
      "Epoch 387/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3184 - val_loss: 1.4294\n",
      "Epoch 388/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3041 - val_loss: 1.4208\n",
      "Epoch 389/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3067 - val_loss: 1.4160\n",
      "Epoch 390/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3098 - val_loss: 1.4283\n",
      "Epoch 391/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3101 - val_loss: 1.4248\n",
      "Epoch 392/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3072 - val_loss: 1.4336\n",
      "Epoch 393/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3076 - val_loss: 1.4314\n",
      "Epoch 394/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3078 - val_loss: 1.4339\n",
      "Epoch 395/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3090 - val_loss: 1.4421\n",
      "Epoch 396/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.3133 - val_loss: 1.4285\n",
      "Epoch 397/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3125 - val_loss: 1.4293\n",
      "Epoch 398/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3057 - val_loss: 1.4345\n",
      "Epoch 399/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3065 - val_loss: 1.4241\n",
      "Epoch 400/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3056 - val_loss: 1.4156\n",
      "Epoch 401/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3098 - val_loss: 1.4282\n",
      "Epoch 402/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3120 - val_loss: 1.4203\n",
      "Epoch 403/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3080 - val_loss: 1.4315\n",
      "Epoch 404/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 1.4301\n",
      "Epoch 405/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3046 - val_loss: 1.4258\n",
      "Epoch 406/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2997 - val_loss: 1.4373\n",
      "Epoch 407/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3061 - val_loss: 1.4217\n",
      "Epoch 408/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2989 - val_loss: 1.4220\n",
      "Epoch 409/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2985 - val_loss: 1.4340\n",
      "Epoch 410/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3072 - val_loss: 1.4322\n",
      "Epoch 411/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3010 - val_loss: 1.4259\n",
      "Epoch 412/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2959 - val_loss: 1.4261\n",
      "Epoch 413/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2992 - val_loss: 1.4234\n",
      "Epoch 414/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2998 - val_loss: 1.4164\n",
      "Epoch 415/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3071 - val_loss: 1.4213\n",
      "Epoch 416/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2987 - val_loss: 1.4295\n",
      "Epoch 417/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2992 - val_loss: 1.4291\n",
      "Epoch 418/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3019 - val_loss: 1.4372\n",
      "Epoch 419/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3073 - val_loss: 1.4353\n",
      "Epoch 420/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2975 - val_loss: 1.4208\n",
      "Epoch 421/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2953 - val_loss: 1.4260\n",
      "Epoch 422/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2947 - val_loss: 1.4246\n",
      "Epoch 423/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2905 - val_loss: 1.4189\n",
      "Epoch 424/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.3011 - val_loss: 1.4133\n",
      "Epoch 425/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2985 - val_loss: 1.4263\n",
      "Epoch 426/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2956 - val_loss: 1.4332\n",
      "Epoch 427/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2942 - val_loss: 1.4384\n",
      "Epoch 428/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2923 - val_loss: 1.4231\n",
      "Epoch 429/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2923 - val_loss: 1.4319\n",
      "Epoch 430/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2974 - val_loss: 1.4345\n",
      "Epoch 431/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2945 - val_loss: 1.4360\n",
      "Epoch 432/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2987 - val_loss: 1.4374\n",
      "Epoch 433/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2919 - val_loss: 1.4322\n",
      "Epoch 434/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2941 - val_loss: 1.4277\n",
      "Epoch 435/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2879 - val_loss: 1.4367\n",
      "Epoch 436/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2938 - val_loss: 1.4375\n",
      "Epoch 437/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2908 - val_loss: 1.4389\n",
      "Epoch 438/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2944 - val_loss: 1.4343\n",
      "Epoch 439/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2885 - val_loss: 1.4342\n",
      "Epoch 440/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2929 - val_loss: 1.4408\n",
      "Epoch 441/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2826 - val_loss: 1.4346\n",
      "Epoch 442/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2880 - val_loss: 1.4384\n",
      "Epoch 443/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2832 - val_loss: 1.4490\n",
      "Epoch 444/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2838 - val_loss: 1.4338\n",
      "Epoch 445/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2823 - val_loss: 1.4392\n",
      "Epoch 446/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2917 - val_loss: 1.4422\n",
      "Epoch 447/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2895 - val_loss: 1.4447\n",
      "Epoch 448/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2921 - val_loss: 1.4380\n",
      "Epoch 449/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2762 - val_loss: 1.4260\n",
      "Epoch 450/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2882 - val_loss: 1.4327\n",
      "Epoch 451/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2795 - val_loss: 1.4178\n",
      "Epoch 452/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2839 - val_loss: 1.4194\n",
      "Epoch 453/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2847 - val_loss: 1.4370\n",
      "Epoch 454/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2806 - val_loss: 1.4328\n",
      "Epoch 455/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2827 - val_loss: 1.4213\n",
      "Epoch 456/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2854 - val_loss: 1.4105\n",
      "Epoch 457/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2814 - val_loss: 1.4362\n",
      "Epoch 458/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2820 - val_loss: 1.4367\n",
      "Epoch 459/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2869 - val_loss: 1.4300\n",
      "Epoch 460/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2831 - val_loss: 1.4288\n",
      "Epoch 461/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2780 - val_loss: 1.4259\n",
      "Epoch 462/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2785 - val_loss: 1.4355\n",
      "Epoch 463/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2757 - val_loss: 1.4390\n",
      "Epoch 464/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 1.4198\n",
      "Epoch 465/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2863 - val_loss: 1.4214\n",
      "Epoch 466/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2802 - val_loss: 1.4233\n",
      "Epoch 467/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2815 - val_loss: 1.4224\n",
      "Epoch 468/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2742 - val_loss: 1.4258\n",
      "Epoch 469/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2753 - val_loss: 1.4335\n",
      "Epoch 470/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2769 - val_loss: 1.4315\n",
      "Epoch 471/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 1.4207\n",
      "Epoch 472/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2742 - val_loss: 1.4273\n",
      "Epoch 473/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2786 - val_loss: 1.4335\n",
      "Epoch 474/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2746 - val_loss: 1.4256\n",
      "Epoch 475/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2761 - val_loss: 1.4383\n",
      "Epoch 476/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2738 - val_loss: 1.4296\n",
      "Epoch 477/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2667 - val_loss: 1.4370\n",
      "Epoch 478/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2722 - val_loss: 1.4316\n",
      "Epoch 479/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2779 - val_loss: 1.4274\n",
      "Epoch 480/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2758 - val_loss: 1.4307\n",
      "Epoch 481/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2775 - val_loss: 1.4167\n",
      "Epoch 482/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2692 - val_loss: 1.4309\n",
      "Epoch 483/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2809 - val_loss: 1.4443\n",
      "Epoch 484/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 1.4259\n",
      "Epoch 485/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 1.4270\n",
      "Epoch 486/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2674 - val_loss: 1.4323\n",
      "Epoch 487/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2660 - val_loss: 1.4328\n",
      "Epoch 488/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 1.4333\n",
      "Epoch 489/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2718 - val_loss: 1.4311\n",
      "Epoch 490/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2672 - val_loss: 1.4227\n",
      "Epoch 491/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 1.4343\n",
      "Epoch 492/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2618 - val_loss: 1.4229\n",
      "Epoch 493/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 1.4334\n",
      "Epoch 494/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2699 - val_loss: 1.4209\n",
      "Epoch 495/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 1.4229\n",
      "Epoch 496/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2705 - val_loss: 1.4184\n",
      "Epoch 497/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2688 - val_loss: 1.4145\n",
      "Epoch 498/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2677 - val_loss: 1.4259\n",
      "Epoch 499/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2753 - val_loss: 1.4318\n",
      "Epoch 500/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 1.4309\n",
      "Epoch 501/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2672 - val_loss: 1.4178\n",
      "Epoch 502/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2755 - val_loss: 1.4285\n",
      "Epoch 503/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2692 - val_loss: 1.4280\n",
      "Epoch 504/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2611 - val_loss: 1.4172\n",
      "Epoch 505/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 1.4048\n",
      "Epoch 506/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2680 - val_loss: 1.4117\n",
      "Epoch 507/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2647 - val_loss: 1.4098\n",
      "Epoch 508/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2704 - val_loss: 1.4235\n",
      "Epoch 509/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2656 - val_loss: 1.4291\n",
      "Epoch 510/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2701 - val_loss: 1.4341\n",
      "Epoch 511/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2763 - val_loss: 1.4257\n",
      "Epoch 512/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2576 - val_loss: 1.4135\n",
      "Epoch 513/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2557 - val_loss: 1.4166\n",
      "Epoch 514/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2614 - val_loss: 1.4290\n",
      "Epoch 515/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2608 - val_loss: 1.4248\n",
      "Epoch 516/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2621 - val_loss: 1.4199\n",
      "Epoch 517/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2612 - val_loss: 1.4200\n",
      "Epoch 518/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2649 - val_loss: 1.4147\n",
      "Epoch 519/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2617 - val_loss: 1.4245\n",
      "Epoch 520/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2561 - val_loss: 1.4229\n",
      "Epoch 521/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2621 - val_loss: 1.4138\n",
      "Epoch 522/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2632 - val_loss: 1.4268\n",
      "Epoch 523/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2639 - val_loss: 1.4277\n",
      "Epoch 524/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2567 - val_loss: 1.4255\n",
      "Epoch 525/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2572 - val_loss: 1.4100\n",
      "Epoch 526/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2624 - val_loss: 1.4291\n",
      "Epoch 527/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2592 - val_loss: 1.4196\n",
      "Epoch 528/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2527 - val_loss: 1.4060\n",
      "Epoch 529/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2570 - val_loss: 1.4174\n",
      "Epoch 530/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2585 - val_loss: 1.4197\n",
      "Epoch 531/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2535 - val_loss: 1.4195\n",
      "Epoch 532/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2490 - val_loss: 1.4227\n",
      "Epoch 533/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2563 - val_loss: 1.4297\n",
      "Epoch 534/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2508 - val_loss: 1.4319\n",
      "Epoch 535/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2570 - val_loss: 1.4211\n",
      "Epoch 536/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2547 - val_loss: 1.4146\n",
      "Epoch 537/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2615 - val_loss: 1.4221\n",
      "Epoch 538/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2523 - val_loss: 1.4221\n",
      "Epoch 539/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2587 - val_loss: 1.4217\n",
      "Epoch 540/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2552 - val_loss: 1.4142\n",
      "Epoch 541/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2568 - val_loss: 1.4181\n",
      "Epoch 542/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2553 - val_loss: 1.4029\n",
      "Epoch 543/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2474 - val_loss: 1.4129\n",
      "Epoch 544/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2521 - val_loss: 1.4099\n",
      "Epoch 545/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2470 - val_loss: 1.4213\n",
      "Epoch 546/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2527 - val_loss: 1.4258\n",
      "Epoch 547/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2499 - val_loss: 1.4186\n",
      "Epoch 548/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 1.4295\n",
      "Epoch 549/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2436 - val_loss: 1.4180\n",
      "Epoch 550/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2483 - val_loss: 1.4170\n",
      "Epoch 551/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2611 - val_loss: 1.4051\n",
      "Epoch 552/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2589 - val_loss: 1.4291\n",
      "Epoch 553/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2551 - val_loss: 1.4165\n",
      "Epoch 554/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2523 - val_loss: 1.4163\n",
      "Epoch 555/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2485 - val_loss: 1.4203\n",
      "Epoch 556/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2510 - val_loss: 1.4175\n",
      "Epoch 557/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2510 - val_loss: 1.4237\n",
      "Epoch 558/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2468 - val_loss: 1.4353\n",
      "Epoch 559/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2500 - val_loss: 1.4227\n",
      "Epoch 560/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2438 - val_loss: 1.4172\n",
      "Epoch 561/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2513 - val_loss: 1.4184\n",
      "Epoch 562/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2527 - val_loss: 1.4256\n",
      "Epoch 563/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2569 - val_loss: 1.4313\n",
      "Epoch 564/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2522 - val_loss: 1.4234\n",
      "Epoch 565/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2480 - val_loss: 1.4224\n",
      "Epoch 566/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2474 - val_loss: 1.4232\n",
      "Epoch 567/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2468 - val_loss: 1.4342\n",
      "Epoch 568/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2454 - val_loss: 1.4172\n",
      "Epoch 569/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2411 - val_loss: 1.4216\n",
      "Epoch 570/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2467 - val_loss: 1.4125\n",
      "Epoch 571/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2388 - val_loss: 1.4019\n",
      "Epoch 572/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2500 - val_loss: 1.4333\n",
      "Epoch 573/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2453 - val_loss: 1.4145\n",
      "Epoch 574/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2463 - val_loss: 1.4198\n",
      "Epoch 575/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2434 - val_loss: 1.4230\n",
      "Epoch 576/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2436 - val_loss: 1.4097\n",
      "Epoch 577/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2443 - val_loss: 1.4111\n",
      "Epoch 578/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2406 - val_loss: 1.4189\n",
      "Epoch 579/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2382 - val_loss: 1.4191\n",
      "Epoch 580/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2387 - val_loss: 1.4174\n",
      "Epoch 581/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2449 - val_loss: 1.4162\n",
      "Epoch 582/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2440 - val_loss: 1.4229\n",
      "Epoch 583/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2435 - val_loss: 1.4192\n",
      "Epoch 584/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2417 - val_loss: 1.4165\n",
      "Epoch 585/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2413 - val_loss: 1.4174\n",
      "Epoch 586/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2391 - val_loss: 1.4317\n",
      "Epoch 587/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2440 - val_loss: 1.4137\n",
      "Epoch 588/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2404 - val_loss: 1.4171\n",
      "Epoch 589/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2395 - val_loss: 1.4175\n",
      "Epoch 590/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 1.4238\n",
      "Epoch 591/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2442 - val_loss: 1.4276\n",
      "Epoch 592/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2433 - val_loss: 1.4252\n",
      "Epoch 593/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 1.4203\n",
      "Epoch 594/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2423 - val_loss: 1.4148\n",
      "Epoch 595/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2352 - val_loss: 1.4211\n",
      "Epoch 596/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2406 - val_loss: 1.4190\n",
      "Epoch 597/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2338 - val_loss: 1.4267\n",
      "Epoch 598/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2324 - val_loss: 1.4178\n",
      "Epoch 599/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2414 - val_loss: 1.4162\n",
      "Epoch 600/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2367 - val_loss: 1.4246\n",
      "Epoch 601/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2392 - val_loss: 1.4155\n",
      "Epoch 602/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2395 - val_loss: 1.4245\n",
      "Epoch 603/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2347 - val_loss: 1.4194\n",
      "Epoch 604/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2382 - val_loss: 1.4170\n",
      "Epoch 605/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2471 - val_loss: 1.4205\n",
      "Epoch 606/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2456 - val_loss: 1.4148\n",
      "Epoch 607/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2421 - val_loss: 1.4160\n",
      "Epoch 608/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2386 - val_loss: 1.4104\n",
      "Epoch 609/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2340 - val_loss: 1.4219\n",
      "Epoch 610/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2325 - val_loss: 1.4141\n",
      "Epoch 611/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2397 - val_loss: 1.4176\n",
      "Epoch 612/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2350 - val_loss: 1.4253\n",
      "Epoch 613/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2377 - val_loss: 1.4338\n",
      "Epoch 614/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2364 - val_loss: 1.4226\n",
      "Epoch 615/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2347 - val_loss: 1.4252\n",
      "Epoch 616/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2389 - val_loss: 1.4309\n",
      "Epoch 617/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2268 - val_loss: 1.4142\n",
      "Epoch 618/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2351 - val_loss: 1.4253\n",
      "Epoch 619/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2373 - val_loss: 1.4233\n",
      "Epoch 620/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2314 - val_loss: 1.4125\n",
      "Epoch 621/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2293 - val_loss: 1.4159\n",
      "Epoch 622/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2348 - val_loss: 1.4063\n",
      "Epoch 623/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2346 - val_loss: 1.4105\n",
      "Epoch 624/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2324 - val_loss: 1.3916\n",
      "Epoch 625/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2290 - val_loss: 1.4125\n",
      "Epoch 626/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2336 - val_loss: 1.4055\n",
      "Epoch 627/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2264 - val_loss: 1.3956\n",
      "Epoch 628/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2328 - val_loss: 1.4043\n",
      "Epoch 629/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2275 - val_loss: 1.4183\n",
      "Epoch 630/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2324 - val_loss: 1.4153\n",
      "Epoch 631/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2334 - val_loss: 1.4096\n",
      "Epoch 632/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2325 - val_loss: 1.4200\n",
      "Epoch 633/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2312 - val_loss: 1.4092\n",
      "Epoch 634/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2295 - val_loss: 1.4149\n",
      "Epoch 635/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2305 - val_loss: 1.4239\n",
      "Epoch 636/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2324 - val_loss: 1.4054\n",
      "Epoch 637/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2292 - val_loss: 1.4100\n",
      "Epoch 638/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2368 - val_loss: 1.4284\n",
      "Epoch 639/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2286 - val_loss: 1.4121\n",
      "Epoch 640/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2283 - val_loss: 1.4265\n",
      "Epoch 641/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2255 - val_loss: 1.4224\n",
      "Epoch 642/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2357 - val_loss: 1.4329\n",
      "Epoch 643/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2276 - val_loss: 1.4115\n",
      "Epoch 644/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2321 - val_loss: 1.4213\n",
      "Epoch 645/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2332 - val_loss: 1.4143\n",
      "Epoch 646/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2232 - val_loss: 1.4174\n",
      "Epoch 647/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2291 - val_loss: 1.4190\n",
      "Epoch 648/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2339 - val_loss: 1.4348\n",
      "Epoch 649/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2310 - val_loss: 1.4218\n",
      "Epoch 650/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2313 - val_loss: 1.4225\n",
      "Epoch 651/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2302 - val_loss: 1.4267\n",
      "Epoch 652/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2225 - val_loss: 1.4213\n",
      "Epoch 653/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2228 - val_loss: 1.4159\n",
      "Epoch 654/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 1.4129\n",
      "Epoch 655/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2303 - val_loss: 1.4228\n",
      "Epoch 656/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2276 - val_loss: 1.4107\n",
      "Epoch 657/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2268 - val_loss: 1.4072\n",
      "Epoch 658/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2304 - val_loss: 1.4165\n",
      "Epoch 659/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2334 - val_loss: 1.4133\n",
      "Epoch 660/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2308 - val_loss: 1.4075\n",
      "Epoch 661/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2320 - val_loss: 1.4128\n",
      "Epoch 662/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2266 - val_loss: 1.4167\n",
      "Epoch 663/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2274 - val_loss: 1.4198\n",
      "Epoch 664/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2277 - val_loss: 1.4310\n",
      "Epoch 665/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2230 - val_loss: 1.4252\n",
      "Epoch 666/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2209 - val_loss: 1.4211\n",
      "Epoch 667/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2164 - val_loss: 1.4078\n",
      "Epoch 668/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2232 - val_loss: 1.4126\n",
      "Epoch 669/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2177 - val_loss: 1.4083\n",
      "Epoch 670/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2265 - val_loss: 1.4259\n",
      "Epoch 671/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2229 - val_loss: 1.4246\n",
      "Epoch 672/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2348 - val_loss: 1.4160\n",
      "Epoch 673/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2260 - val_loss: 1.4095\n",
      "Epoch 674/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2265 - val_loss: 1.4210\n",
      "Epoch 675/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2239 - val_loss: 1.4081\n",
      "Epoch 676/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2268 - val_loss: 1.4192\n",
      "Epoch 677/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2266 - val_loss: 1.4101\n",
      "Epoch 678/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2232 - val_loss: 1.4122\n",
      "Epoch 679/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2314 - val_loss: 1.4214\n",
      "Epoch 680/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2218 - val_loss: 1.3998\n",
      "Epoch 681/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2212 - val_loss: 1.4082\n",
      "Epoch 682/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2226 - val_loss: 1.4176\n",
      "Epoch 683/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2257 - val_loss: 1.4043\n",
      "Epoch 684/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2192 - val_loss: 1.4121\n",
      "Epoch 685/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2198 - val_loss: 1.4046\n",
      "Epoch 686/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2193 - val_loss: 1.4039\n",
      "Epoch 687/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2199 - val_loss: 1.4082\n",
      "Epoch 688/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2184 - val_loss: 1.4058\n",
      "Epoch 689/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2196 - val_loss: 1.4103\n",
      "Epoch 690/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2234 - val_loss: 1.4124\n",
      "Epoch 691/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2227 - val_loss: 1.4126\n",
      "Epoch 692/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2217 - val_loss: 1.4199\n",
      "Epoch 693/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2211 - val_loss: 1.4093\n",
      "Epoch 694/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2167 - val_loss: 1.4123\n",
      "Epoch 695/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2222 - val_loss: 1.4150\n",
      "Epoch 696/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2187 - val_loss: 1.4194\n",
      "Epoch 697/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2202 - val_loss: 1.4136\n",
      "Epoch 698/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2181 - val_loss: 1.4276\n",
      "Epoch 699/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2254 - val_loss: 1.4176\n",
      "Epoch 700/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2230 - val_loss: 1.4132\n",
      "Epoch 701/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2198 - val_loss: 1.4195\n",
      "Epoch 702/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2185 - val_loss: 1.4163\n",
      "Epoch 703/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2142 - val_loss: 1.4097\n",
      "Epoch 704/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2264 - val_loss: 1.4212\n",
      "Epoch 705/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2224 - val_loss: 1.4192\n",
      "Epoch 706/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2170 - val_loss: 1.4214\n",
      "Epoch 707/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2183 - val_loss: 1.4117\n",
      "Epoch 708/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2185 - val_loss: 1.4184\n",
      "Epoch 709/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2186 - val_loss: 1.4249\n",
      "Epoch 710/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2153 - val_loss: 1.4195\n",
      "Epoch 711/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2174 - val_loss: 1.4187\n",
      "Epoch 712/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2192 - val_loss: 1.4263\n",
      "Epoch 713/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2188 - val_loss: 1.4248\n",
      "Epoch 714/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2192 - val_loss: 1.4236\n",
      "Epoch 715/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2086 - val_loss: 1.4138\n",
      "Epoch 716/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2154 - val_loss: 1.4058\n",
      "Epoch 717/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2187 - val_loss: 1.4140\n",
      "Epoch 718/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2182 - val_loss: 1.4220\n",
      "Epoch 719/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2184 - val_loss: 1.4300\n",
      "Epoch 720/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2084 - val_loss: 1.4201\n",
      "Epoch 721/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2139 - val_loss: 1.4204\n",
      "Epoch 722/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2128 - val_loss: 1.4096\n",
      "Epoch 723/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2156 - val_loss: 1.4122\n",
      "Epoch 724/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2083 - val_loss: 1.4147\n",
      "Epoch 725/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2170 - val_loss: 1.4209\n",
      "Epoch 726/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2156 - val_loss: 1.4068\n",
      "Epoch 727/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2136 - val_loss: 1.4165\n",
      "Epoch 728/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2059 - val_loss: 1.4171\n",
      "Epoch 729/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2172 - val_loss: 1.4148\n",
      "Epoch 730/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2257 - val_loss: 1.4304\n",
      "Epoch 731/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2232 - val_loss: 1.4139\n",
      "Epoch 732/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2288 - val_loss: 1.4159\n",
      "Epoch 733/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2117 - val_loss: 1.4186\n",
      "Epoch 734/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2103 - val_loss: 1.4216\n",
      "Epoch 735/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2114 - val_loss: 1.4080\n",
      "Epoch 736/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2202 - val_loss: 1.4191\n",
      "Epoch 737/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2209 - val_loss: 1.4165\n",
      "Epoch 738/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2135 - val_loss: 1.4133\n",
      "Epoch 739/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2131 - val_loss: 1.4213\n",
      "Epoch 740/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2088 - val_loss: 1.4167\n",
      "Epoch 741/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2075 - val_loss: 1.4119\n",
      "Epoch 742/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 1.4186\n",
      "Epoch 743/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2108 - val_loss: 1.4066\n",
      "Epoch 744/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2157 - val_loss: 1.4181\n",
      "Epoch 745/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2123 - val_loss: 1.4072\n",
      "Epoch 746/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2114 - val_loss: 1.4163\n",
      "Epoch 747/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 1.4060\n",
      "Epoch 748/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 1.4319\n",
      "Epoch 749/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2093 - val_loss: 1.4265\n",
      "Epoch 750/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2107 - val_loss: 1.4175\n",
      "Epoch 751/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2100 - val_loss: 1.4248\n",
      "Epoch 752/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2151 - val_loss: 1.4263\n",
      "Epoch 753/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2085 - val_loss: 1.4190\n",
      "Epoch 754/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2148 - val_loss: 1.4320\n",
      "Epoch 755/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2064 - val_loss: 1.4230\n",
      "Epoch 756/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 1.4255\n",
      "Epoch 757/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2047 - val_loss: 1.4118\n",
      "Epoch 758/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2063 - val_loss: 1.4289\n",
      "Epoch 759/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2103 - val_loss: 1.4176\n",
      "Epoch 760/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2033 - val_loss: 1.4257\n",
      "Epoch 761/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2137 - val_loss: 1.4382\n",
      "Epoch 762/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2034 - val_loss: 1.4239\n",
      "Epoch 763/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2097 - val_loss: 1.4219\n",
      "Epoch 764/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2076 - val_loss: 1.4223\n",
      "Epoch 765/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 1.4269\n",
      "Epoch 766/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2068 - val_loss: 1.4250\n",
      "Epoch 767/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2063 - val_loss: 1.4170\n",
      "Epoch 768/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2055 - val_loss: 1.4299\n",
      "Epoch 769/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2102 - val_loss: 1.4148\n",
      "Epoch 770/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2108 - val_loss: 1.4262\n",
      "Epoch 771/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2096 - val_loss: 1.4218\n",
      "Epoch 772/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2083 - val_loss: 1.4242\n",
      "Epoch 773/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2097 - val_loss: 1.4261\n",
      "Epoch 774/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 1.4200\n",
      "Epoch 775/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2041 - val_loss: 1.4366\n",
      "Epoch 776/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2054 - val_loss: 1.4304\n",
      "Epoch 777/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2093 - val_loss: 1.4348\n",
      "Epoch 778/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2079 - val_loss: 1.4364\n",
      "Epoch 779/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2094 - val_loss: 1.4167\n",
      "Epoch 780/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2108 - val_loss: 1.4262\n",
      "Epoch 781/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2052 - val_loss: 1.4166\n",
      "Epoch 782/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2112 - val_loss: 1.4208\n",
      "Epoch 783/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2091 - val_loss: 1.4263\n",
      "Epoch 784/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2070 - val_loss: 1.4285\n",
      "Epoch 785/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2067 - val_loss: 1.4254\n",
      "Epoch 786/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 1.4169\n",
      "Epoch 787/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1999 - val_loss: 1.4219\n",
      "Epoch 788/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2050 - val_loss: 1.4112\n",
      "Epoch 789/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1942 - val_loss: 1.4159\n",
      "Epoch 790/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2035 - val_loss: 1.4202\n",
      "Epoch 791/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2104 - val_loss: 1.4278\n",
      "Epoch 792/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 1.4200\n",
      "Epoch 793/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2095 - val_loss: 1.4281\n",
      "Epoch 794/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2136 - val_loss: 1.4330\n",
      "Epoch 795/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2055 - val_loss: 1.4223\n",
      "Epoch 796/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2033 - val_loss: 1.4102\n",
      "Epoch 797/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2018 - val_loss: 1.4142\n",
      "Epoch 798/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1975 - val_loss: 1.4243\n",
      "Epoch 799/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 1.4172\n",
      "Epoch 800/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2079 - val_loss: 1.4190\n",
      "Epoch 801/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 1.4175\n",
      "Epoch 802/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1983 - val_loss: 1.4247\n",
      "Epoch 803/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 1.4205\n",
      "Epoch 804/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 1.4152\n",
      "Epoch 805/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 1.4144\n",
      "Epoch 806/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 1.4215\n",
      "Epoch 807/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1969 - val_loss: 1.4218\n",
      "Epoch 808/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1995 - val_loss: 1.4318\n",
      "Epoch 809/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 1.4455\n",
      "Epoch 810/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2088 - val_loss: 1.4387\n",
      "Epoch 811/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 1.4241\n",
      "Epoch 812/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 1.4129\n",
      "Epoch 813/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2020 - val_loss: 1.4180\n",
      "Epoch 814/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1972 - val_loss: 1.4302\n",
      "Epoch 815/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1987 - val_loss: 1.4182\n",
      "Epoch 816/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1963 - val_loss: 1.4245\n",
      "Epoch 817/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 1.4180\n",
      "Epoch 818/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2017 - val_loss: 1.4244\n",
      "Epoch 819/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1978 - val_loss: 1.4175\n",
      "Epoch 820/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2043 - val_loss: 1.4281\n",
      "Epoch 821/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1969 - val_loss: 1.4269\n",
      "Epoch 822/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 1.4217\n",
      "Epoch 823/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 1.4287\n",
      "Epoch 824/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1983 - val_loss: 1.4336\n",
      "Epoch 825/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2020 - val_loss: 1.4260\n",
      "Epoch 826/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1972 - val_loss: 1.4333\n",
      "Epoch 827/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1991 - val_loss: 1.4227\n",
      "Epoch 828/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1945 - val_loss: 1.4214\n",
      "Epoch 829/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2070 - val_loss: 1.4271\n",
      "Epoch 830/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2010 - val_loss: 1.4272\n",
      "Epoch 831/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1971 - val_loss: 1.4298\n",
      "Epoch 832/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 1.4276\n",
      "Epoch 833/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2071 - val_loss: 1.4410\n",
      "Epoch 834/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2117 - val_loss: 1.4381\n",
      "Epoch 835/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1998 - val_loss: 1.4272\n",
      "Epoch 836/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 1.4252\n",
      "Epoch 837/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1973 - val_loss: 1.4167\n",
      "Epoch 838/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1932 - val_loss: 1.4200\n",
      "Epoch 839/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1984 - val_loss: 1.4099\n",
      "Epoch 840/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1984 - val_loss: 1.4155\n",
      "Epoch 841/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1956 - val_loss: 1.4165\n",
      "Epoch 842/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2002 - val_loss: 1.4210\n",
      "Epoch 843/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1982 - val_loss: 1.4332\n",
      "Epoch 844/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 1.4277\n",
      "Epoch 845/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1979 - val_loss: 1.4204\n",
      "Epoch 846/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1957 - val_loss: 1.4417\n",
      "Epoch 847/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1994 - val_loss: 1.4196\n",
      "Epoch 848/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2006 - val_loss: 1.4296\n",
      "Epoch 849/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 1.4179\n",
      "Epoch 850/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1950 - val_loss: 1.4228\n",
      "Epoch 851/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1968 - val_loss: 1.4260\n",
      "Epoch 852/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 1.4322\n",
      "Epoch 853/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 1.4217\n",
      "Epoch 854/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2003 - val_loss: 1.4245\n",
      "Epoch 855/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 1.4160\n",
      "Epoch 856/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1997 - val_loss: 1.4236\n",
      "Epoch 857/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1936 - val_loss: 1.4236\n",
      "Epoch 858/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1987 - val_loss: 1.4289\n",
      "Epoch 859/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1995 - val_loss: 1.4193\n",
      "Epoch 860/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1990 - val_loss: 1.4234\n",
      "Epoch 861/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1991 - val_loss: 1.4244\n",
      "Epoch 862/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.2015 - val_loss: 1.4361\n",
      "Epoch 863/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1965 - val_loss: 1.4165\n",
      "Epoch 864/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1939 - val_loss: 1.4144\n",
      "Epoch 865/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1911 - val_loss: 1.4227\n",
      "Epoch 866/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1978 - val_loss: 1.4289\n",
      "Epoch 867/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1997 - val_loss: 1.4291\n",
      "Epoch 868/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1886 - val_loss: 1.4234\n",
      "Epoch 869/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1929 - val_loss: 1.4266\n",
      "Epoch 870/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1934 - val_loss: 1.4274\n",
      "Epoch 871/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1942 - val_loss: 1.4256\n",
      "Epoch 872/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1933 - val_loss: 1.4146\n",
      "Epoch 873/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1954 - val_loss: 1.4287\n",
      "Epoch 874/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1917 - val_loss: 1.4244\n",
      "Epoch 875/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1889 - val_loss: 1.4161\n",
      "Epoch 876/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1883 - val_loss: 1.4209\n",
      "Epoch 877/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1907 - val_loss: 1.4307\n",
      "Epoch 878/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1928 - val_loss: 1.4265\n",
      "Epoch 879/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1915 - val_loss: 1.4198\n",
      "Epoch 880/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1945 - val_loss: 1.4189\n",
      "Epoch 881/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1936 - val_loss: 1.4165\n",
      "Epoch 882/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1888 - val_loss: 1.4223\n",
      "Epoch 883/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1891 - val_loss: 1.4126\n",
      "Epoch 884/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1926 - val_loss: 1.4044\n",
      "Epoch 885/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1995 - val_loss: 1.4124\n",
      "Epoch 886/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2002 - val_loss: 1.4016\n",
      "Epoch 887/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1854 - val_loss: 1.4064\n",
      "Epoch 888/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 1.4213\n",
      "Epoch 889/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1924 - val_loss: 1.4198\n",
      "Epoch 890/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1942 - val_loss: 1.4198\n",
      "Epoch 891/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1921 - val_loss: 1.4238\n",
      "Epoch 892/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1967 - val_loss: 1.4238\n",
      "Epoch 893/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1924 - val_loss: 1.4240\n",
      "Epoch 894/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1903 - val_loss: 1.4298\n",
      "Epoch 895/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1906 - val_loss: 1.4262\n",
      "Epoch 896/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 1.4105\n",
      "Epoch 897/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1999 - val_loss: 1.4208\n",
      "Epoch 898/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1956 - val_loss: 1.4174\n",
      "Epoch 899/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1853 - val_loss: 1.4103\n",
      "Epoch 900/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1883 - val_loss: 1.4203\n",
      "Epoch 901/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1886 - val_loss: 1.4205\n",
      "Epoch 902/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1834 - val_loss: 1.4337\n",
      "Epoch 903/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1970 - val_loss: 1.4056\n",
      "Epoch 904/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1865 - val_loss: 1.4042\n",
      "Epoch 905/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1983 - val_loss: 1.4101\n",
      "Epoch 906/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1857 - val_loss: 1.4189\n",
      "Epoch 907/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1899 - val_loss: 1.4160\n",
      "Epoch 908/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1827 - val_loss: 1.4087\n",
      "Epoch 909/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1870 - val_loss: 1.4219\n",
      "Epoch 910/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1865 - val_loss: 1.4318\n",
      "Epoch 911/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1889 - val_loss: 1.4145\n",
      "Epoch 912/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1916 - val_loss: 1.4101\n",
      "Epoch 913/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1846 - val_loss: 1.4173\n",
      "Epoch 914/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1931 - val_loss: 1.4148\n",
      "Epoch 915/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1872 - val_loss: 1.4154\n",
      "Epoch 916/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1881 - val_loss: 1.4331\n",
      "Epoch 917/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1977 - val_loss: 1.4267\n",
      "Epoch 918/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1938 - val_loss: 1.4353\n",
      "Epoch 919/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1895 - val_loss: 1.4224\n",
      "Epoch 920/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1860 - val_loss: 1.4208\n",
      "Epoch 921/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1895 - val_loss: 1.4152\n",
      "Epoch 922/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1883 - val_loss: 1.4175\n",
      "Epoch 923/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1884 - val_loss: 1.4208\n",
      "Epoch 924/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1910 - val_loss: 1.4146\n",
      "Epoch 925/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1813 - val_loss: 1.4129\n",
      "Epoch 926/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1921 - val_loss: 1.4247\n",
      "Epoch 927/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1841 - val_loss: 1.4155\n",
      "Epoch 928/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1946 - val_loss: 1.4208\n",
      "Epoch 929/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1892 - val_loss: 1.4298\n",
      "Epoch 930/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1828 - val_loss: 1.4208\n",
      "Epoch 931/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1902 - val_loss: 1.4101\n",
      "Epoch 932/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1862 - val_loss: 1.4281\n",
      "Epoch 933/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1798 - val_loss: 1.4239\n",
      "Epoch 934/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1876 - val_loss: 1.4224\n",
      "Epoch 935/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1880 - val_loss: 1.4176\n",
      "Epoch 936/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1886 - val_loss: 1.4183\n",
      "Epoch 937/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1877 - val_loss: 1.4215\n",
      "Epoch 938/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1811 - val_loss: 1.4119\n",
      "Epoch 939/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1856 - val_loss: 1.4242\n",
      "Epoch 940/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1842 - val_loss: 1.4071\n",
      "Epoch 941/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1877 - val_loss: 1.4241\n",
      "Epoch 942/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1936 - val_loss: 1.4016\n",
      "Epoch 943/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1869 - val_loss: 1.4079\n",
      "Epoch 944/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1847 - val_loss: 1.4198\n",
      "Epoch 945/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1872 - val_loss: 1.4080\n",
      "Epoch 946/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1850 - val_loss: 1.4260\n",
      "Epoch 947/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1840 - val_loss: 1.4117\n",
      "Epoch 948/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1895 - val_loss: 1.4270\n",
      "Epoch 949/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1881 - val_loss: 1.4208\n",
      "Epoch 950/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1839 - val_loss: 1.4279\n",
      "Epoch 951/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1950 - val_loss: 1.4153\n",
      "Epoch 952/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1929 - val_loss: 1.4260\n",
      "Epoch 953/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1877 - val_loss: 1.4306\n",
      "Epoch 954/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1854 - val_loss: 1.4312\n",
      "Epoch 955/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1895 - val_loss: 1.4123\n",
      "Epoch 956/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1819 - val_loss: 1.4303\n",
      "Epoch 957/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1779 - val_loss: 1.4294\n",
      "Epoch 958/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1904 - val_loss: 1.4222\n",
      "Epoch 959/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1926 - val_loss: 1.4383\n",
      "Epoch 960/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1852 - val_loss: 1.4185\n",
      "Epoch 961/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1873 - val_loss: 1.4264\n",
      "Epoch 962/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1856 - val_loss: 1.4124\n",
      "Epoch 963/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1875 - val_loss: 1.4198\n",
      "Epoch 964/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1840 - val_loss: 1.4165\n",
      "Epoch 965/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1794 - val_loss: 1.4170\n",
      "Epoch 966/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1890 - val_loss: 1.4113\n",
      "Epoch 967/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1816 - val_loss: 1.3984\n",
      "Epoch 968/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1792 - val_loss: 1.4122\n",
      "Epoch 969/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1754 - val_loss: 1.4160\n",
      "Epoch 970/1000\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.1851 - val_loss: 1.4144\n",
      "Epoch 971/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1828 - val_loss: 1.4226\n",
      "Epoch 972/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1783 - val_loss: 1.4177\n",
      "Epoch 973/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1879 - val_loss: 1.4174\n",
      "Epoch 974/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1822 - val_loss: 1.4208\n",
      "Epoch 975/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1849 - val_loss: 1.4157\n",
      "Epoch 976/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1871 - val_loss: 1.4175\n",
      "Epoch 977/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1858 - val_loss: 1.4182\n",
      "Epoch 978/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1815 - val_loss: 1.4112\n",
      "Epoch 979/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1782 - val_loss: 1.4213\n",
      "Epoch 980/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1814 - val_loss: 1.4113\n",
      "Epoch 981/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1823 - val_loss: 1.4029\n",
      "Epoch 982/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1851 - val_loss: 1.4071\n",
      "Epoch 983/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1871 - val_loss: 1.4059\n",
      "Epoch 984/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1883 - val_loss: 1.4226\n",
      "Epoch 985/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1842 - val_loss: 1.4170\n",
      "Epoch 986/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1875 - val_loss: 1.4188\n",
      "Epoch 987/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1835 - val_loss: 1.4177\n",
      "Epoch 988/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1851 - val_loss: 1.4261\n",
      "Epoch 989/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1783 - val_loss: 1.4118\n",
      "Epoch 990/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1872 - val_loss: 1.4052\n",
      "Epoch 991/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1846 - val_loss: 1.4092\n",
      "Epoch 992/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1811 - val_loss: 1.4177\n",
      "Epoch 993/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1814 - val_loss: 1.4266\n",
      "Epoch 994/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1803 - val_loss: 1.4146\n",
      "Epoch 995/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1818 - val_loss: 1.4099\n",
      "Epoch 996/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1807 - val_loss: 1.4159\n",
      "Epoch 997/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1823 - val_loss: 1.4314\n",
      "Epoch 998/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1820 - val_loss: 1.4132\n",
      "Epoch 999/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1857 - val_loss: 1.4222\n",
      "Epoch 1000/1000\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.1816 - val_loss: 1.4256\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "        loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=125, restore_best_weights=True)\n",
    "\n",
    "h = model.fit(\n",
    "    data_train,\n",
    "    labels_train,\n",
    "    epochs=1000,\n",
    "    batch_size=150,\n",
    "    validation_data=(data_validation, labels_validation),\n",
    "    # callbacks=[early_stop]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 1s 1ms/step\n",
      "\n",
      "Values for validation set:\n",
      "MAE: 0.088007918001174\n",
      "MSE: 0.058634782125115234\n",
      "RMSE: 0.24214619989815087\n",
      "R2:  0.9903578001419397\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data_train)\n",
    "mae, mse, r2 = get_score(labels_train, predictions)\n",
    "print(f'''\\nValues for validation set:\\nMAE: {mae}\\nMSE: {mse}\\nRMSE: {mse**.5}\\nR2:  {r2}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 1ms/step\n",
      "\n",
      "Values for validation set:\n",
      "MAE: 1.4461617082163571\n",
      "MSE: 5.511819239730513\n",
      "RMSE: 2.3477263979711336\n",
      "R2:  0.08610390972147103\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data_test)\n",
    "mae, mse, r2 = get_score(labels_test, predictions)\n",
    "print(f'''\\nValues for validation set:\\nMAE: {mae}\\nMSE: {mse}\\nRMSE: {mse**.5}\\nR2:  {r2}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
